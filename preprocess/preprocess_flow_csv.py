# preprocess_flow_csv.py

import pandas as pd
import os
from sklearn.preprocessing import MinMaxScaler
import joblib
import numpy as np # numpy import ì¶”ê°€

# --- ê²½ë¡œ ì„¤ì • ---
RAW_DATA_DIR = '../data/raw'  # ì›ë³¸ ë°ì´í„° ìœ„ì¹˜
PROCESSED_DATA_DIR = '../data/processed' # ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ìœ„ì¹˜
os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)

# --- í•¨ìˆ˜ ì •ì˜ ---
def preprocess_and_load(path: str) -> pd.DataFrame:
    """
    ë‹¨ì¼ íŒŒì¼ì„ ì½ê³  ê¸°ë³¸ì ì¸ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•œ í›„,
    ë°ì´í„°í”„ë ˆì„ì„ ë°˜í™˜í•©ë‹ˆë‹¤. (ìŠ¤ì¼€ì¼ë§ ë° ì €ì¥ì€ ì œì™¸)
    """
    print(f"ğŸ“‚ Loading and cleaning {os.path.basename(path)}...")
    df = pd.read_csv(path, low_memory=False)

    # 1. ë¼ë²¨ ì»¬ëŸ¼ ì œê±°
    if 'Label' in df.columns:
        df = df.drop(columns=['Label'])

    # 2. ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
    numeric_df = df.select_dtypes(include=[np.number]) # np.numberë¡œ ë” ì•ˆì •ì ìœ¼ë¡œ ì„ íƒ

    # 3. ê²°ì¸¡ì¹˜(NaN) ë° ë¬´í•œê°’(inf)ì´ í¬í•¨ëœ í–‰ ì œê±°
    shape_before = numeric_df.shape
    numeric_df.replace([np.inf, -np.inf], np.nan, inplace=True)
    numeric_df.dropna(inplace=True)
    print(f"    - Shape changed from {shape_before} to {numeric_df.shape} after dropping NaN/Inf.")

    return numeric_df

# === ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ ===
if __name__ == '__main__':
    
    # 1. ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„ì„ ë‹´ì„ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    benign_df_list = []

    # 2. BenignTraffic íŒŒì¼ë“¤ì„ ìˆœíšŒí•˜ë©° ì „ì²˜ë¦¬ í›„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
    print("--- Starting to process Benign traffic files ---")
    for filename in os.listdir(RAW_DATA_DIR):
        if filename.startswith('BenignTraffic') and filename.endswith('pcap_Flow.csv'):
            file_path = os.path.join(RAW_DATA_DIR, filename)
            processed_df = preprocess_and_load(path=file_path)
            benign_df_list.append(processed_df)

    # 3. ë¦¬ìŠ¤íŠ¸ì— ìˆ˜ì§‘ëœ ëª¨ë“  ë°ì´í„°í”„ë ˆì„ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
    if benign_df_list:
        print("\n--- Concatenating all processed files ---")
        # ê³µí†µëœ ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ í•©ì¹˜ê³ , ì—†ëŠ” ì»¬ëŸ¼ì€ NaNìœ¼ë¡œ ì²˜ë¦¬ í›„ ì œê±°
        final_benign_df = pd.concat(benign_df_list, ignore_index=True, join='inner')

        # 4. ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ìŠ¤ì¼€ì¼ëŸ¬ ì ìš©
        print("--- Scaling the final combined dataframe ---")
        scaler = MinMaxScaler()
        # ë°ì´í„°í”„ë ˆì„ì˜ ëª¨ë“  ê°’ì„ floatìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ìŠ¤ì¼€ì¼ëŸ¬ ì˜¤ë¥˜ ë°©ì§€
        final_benign_df = final_benign_df.astype(float)
        
        scaled_values = scaler.fit_transform(final_benign_df)
        scaled_df = pd.DataFrame(scaled_values, columns=final_benign_df.columns)

        # 5. ìµœì¢… ê²°ê³¼ë¬¼ ë° ìŠ¤ì¼€ì¼ëŸ¬, ì»¬ëŸ¼ ì •ë³´ ì €ì¥
        print("--- Saving final artifacts ---")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
        scaler_path = os.path.join(PROCESSED_DATA_DIR, 'scaler.pkl')
        joblib.dump(scaler, scaler_path)
        print(f"âœ… Scaler saved to {scaler_path}")

        # ì»¬ëŸ¼ ì •ë³´ ì €ì¥
        columns_path = os.path.join(PROCESSED_DATA_DIR, 'columns.pkl')
        joblib.dump(scaled_df.columns.tolist(), columns_path)
        print(f"âœ… Columns list saved to {columns_path}")

        # ìµœì¢… ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
        output_path = os.path.join(PROCESSED_DATA_DIR, 'benign_processed.csv')
        scaled_df.to_csv(output_path, index=False)
        print(f"âœ… Final processed data saved to {output_path}, with shape {scaled_df.shape}")

    else:
        print("No 'BenignTraffic' files found to process.")